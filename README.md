<<<<<<< HEAD
<div align="center">
[English](README.md) | [ä¸­æ–‡](README-CN.md)

</div>

# WaveDSNet: Wavelet Dynamic Convolution with Dual-Stream Synergistic Fusion Network

This is the official PyTorch implementation of the paper **"WaveDSNet: Wavelet Dynamic Convolution with Dual-Stream Synergistic Fusion Network for SAR Water Change Detection"**.

This project proposes an end-to-end SAR water change detection network and achieves state-of-the-art performance on the newly constructed large-scale benchmark dataset **XDU-SWCD**.

## ğŸ—ï¸ Network Architecture

<img src="assert\architecture.png" alt="image-20251226142349516" style="zoom: 25%;" />
WaveDSNet adopts a siamese encoder structure that processes bi-temporal SAR images through three synergistic modules to address specific challenges in SAR change detection.

## ğŸš€ Introduction

SAR water change detection faces challenges including speckle noise interference, insufficient semantic interaction, and weak boundary ambiguity. To address these issues, we propose **WaveDSNet**, which contains the following core components:

- **WTCSwinTransformer Backbone**: Combining Wavelet Transform with CSwin Transformer, this backbone utilizes the **WNS (Wavelet-based Noise Suppression)** module to decouple speckle noise from structural semantics in the frequency domain.

  <img src="assert\WTCSWinTransformer.png" alt="image-20251226142349516" style="zoom: 25%;" />

  **Workflow**: First, the CSwin Transformer block processes input images using cross-shaped window attention mechanism to capture long-range dependencies and understand scene semantics. Then, feature maps enter the WNS module where Discrete Wavelet Transform decomposes them into four subbands: one low-frequency subband representing overall contours and uniform areas, and three high-frequency subbands containing details, edges, and noise. For each subband, adaptive convolutional kernels are generated - acting as smoothers in low-frequency regions to suppress random noise, and edge enhancers in boundary regions. This content-aware mechanism avoids detail loss from uniform denoising. Processed subbands are merged through inverse wavelet transform, ensuring noise suppression while preserving important structures.

- **CSDI (Complementary Semantic Difference Interaction)**: This module promotes complementary fusion between semantic features and difference features through bidirectional attention mechanism.

  <img src="assert\CSDI.png" alt="CSDI" style="zoom: 25%;" />

  **Workflow**: Input multi-level semantic features and difference features are projected into query, key, and value vectors through convolutional layers. For computational efficiency, feature maps are divided into local windows where attention is computed. Bidirectional attention calculation includes:

  - Direction 1 (semantic to difference): Interaction between semantic queries and difference keys evaluates how semantic context influences change regions.
  - Direction 2 (difference to semantic): Interaction between difference queries and semantic keys assesses how change signals modify semantic understanding. 

  Outputs from both directions are concatenated and adaptively fused through gating mechanism, where gate weights determine the reliance on semantic or difference information at each position. The fused features emphasize change-relevant regions while reducing false alarms.

- **BASE (Boundary-Aware Supervised Extraction)**: This module imposes explicit geometric constraints to optimize boundary localization accuracy.

  <img src="assert\BASE.png" alt="BASE" style="zoom: 25%;" />
  
  The main branch focuses on pixel-level classification (changed/unchanged) using convolutional layers and upsampling operations to gradually restore resolution and output change probability maps. The auxiliary branch specifically captures boundaries by applying early upsampling to amplify feature maps, then using convolutional layers to extract edge responses. Both branches share features but have different focuses - the change branch ensures overall region accuracy while the edge branch forces the network to learn boundary topology. During training, the loss function combines change loss and edge loss with balanced weights. The final change map integrates results from both branches, producing smoother and more continuous boundaries.
  
  

## ğŸŒŸ Main Features

- **Frequency Domain Denoising**: Introduces wavelet dynamic convolution for adaptive processing of multiplicative noise in SAR images

- **Dual-Stream Synergy**: Deep interaction between semantic and difference streams effectively reduces false alarms.

- **High-Precision Boundaries**: Specialized edge supervision branch resolves ambiguity in water-land interfaces.

- **SOTA Performance**: Significantly outperforms existing methods on both XDU-SWCD and public datasets

  

## ğŸ“Š XDU-SWCD Dataset

To address data scarcity, we constructed the **XDU-SWCD** dataset containing diverse hydrological scenarios.

<img src="assert\dataset.png" alt="dataset" style="zoom: 25%;" />

|        **Region**        |    **Time Period**     |  Sensor  |   Size    | Resolution | Band | Polarization | Classes | Samples |
| :----------------------: | :--------------------: | :------: | :-------: | :--------: | :--: | :----------: | :-----: | :-----: |
|        **Xi'an**         | 2019-01-05  2019-06-29 | **GF-3** | 7199Ã—7516 |     3m     |  C   |      HH      |    2    |   870   |
|   **Xi'an & Xianyang**   | 2019-06-29  2020-09-23 | **GF-3** | 5490Ã—8250 |     3m     |  C   |      HH      |    2    |   726   |
|       **Xianyang**       | 2019-06-29  2019-11-04 | **GF-3** | 6219Ã—6473 |     3m     |  C   |      HH      |    2    |   650   |
| **Xianyang & Tongchuan** | 2019-12-03  2020-09-23 | **GF-3** | 7393Ã—8266 |     3m     |  C   |      HH      |    2    |   957   |

- **Sensor**: GF-3 (C-band SAR)
- **Resolution**: 3 meters (HH polarization)
- **Scale**: 3,203 sample pairs (covering river basins in Xi'an, Xianyang, Tongchuan)**Challenges**: Includes dry/wet season changes and challenging negative samples (like paddy fields)

Download:ï¼š[Baidu Netdisk](https://pan.baidu.com/s/1lzr1wbQqFq-dxxWaW1NHhg?pwd=vf6e)  | [Google Drive](https://drive.google.com/file/d/1YcoNoKniScIT8QeggGRZXJCP6zRP-fp_/view?usp=drive_link)

## ğŸ› ï¸ Installation

This project is developed based on PyTorch.

```bash
# Clone repository
git clone https://github.com/gosling123456/WaveDSNet.git
cd WaveDSNet

# Create virtual environment
conda create -n waved python=3.10
conda activate waved

# Install dependencies
pip install -r requirements.txt
```

## âš¡  Quick Start

### 1.  Data Preparation

Organize data in the following structure:

```
data/
â”œâ”€â”€ XDU-SWCD/
â”‚   â”œâ”€â”€ A/
â”‚   â”œâ”€â”€ B/
â”‚   â”œâ”€â”€ label/
â”‚   â”œâ”€â”€ list/
â”‚   â”‚   â”œâ”€â”€ train.txt/
â”‚   â”‚   â”œâ”€â”€ test.txt/
â”‚   â”‚   â”œâ”€â”€ val.txt/
```

### 2. Training

```bash
python train.py --dataset XDU-SWCD --batch_size 16 --lr 1e-3 --epochs 100
```

*Note: Hyperparameters reference Experiment A section - LR=1e-3, Batch=16, GPUs=2Ã—RTX 5090, Optimizer=AdamW*

)

### 3. Testing

```bash
python test.py --checkpoint checkpoints/best_model.pth --output_dir results/
```

## ğŸ“ˆ Experimental Results

### 1. Performance on Xi'an Dataset

<img src="assert\xian.png" alt="xian_result" style="zoom: 25%;" />

<img src="assert\Xian_result.png" alt="Xian_result" style="zoom: 100%;" />



### 2.  Zero-shot Generalization on Public Datasets

<img src="assert\public.png" alt="public" style="zoom: 25%;" />



<img src="assert\public_result.png" alt="public_result" style="zoom: 100%;" />

## ğŸ”— Citation

If you find this project helpful for your research, please consider citing our paper:

```
###
```

## ğŸ“„ License

This project follows the [MIT License](https://www.google.com/search?q=LICENSE).

=======
# WaveDSNet: Wavelet Dynamic Convolution with Dual-Stream Synergistic Fusion Network

è¿™æ˜¯è®ºæ–‡ **"WaveDSNet: Wavelet Dynamic Convolution with Dual-Stream Synergistic Fusion Network for SAR Water Change Detection"** çš„å®˜æ–¹ PyTorch å®ç°ä»£ç ã€‚

è¯¥é¡¹ç›®æå‡ºäº†ä¸€ç§ç«¯åˆ°ç«¯çš„ SAR æ°´ä½“å˜åŒ–æ£€æµ‹ç½‘ç»œï¼Œå¹¶åœ¨æ–°å»ºçš„å¤§è§„æ¨¡åŸºå‡†æ•°æ®é›† **XDU-SWCD** ä¸Šå–å¾—äº† SOTA æ€§èƒ½ ã€‚

## ğŸ—ï¸ ç½‘ç»œæ¶æ„ (Architecture)

<img src="assert\architecture.png" alt="image-20251226142349516" style="zoom: 25%;" />
WaveDSNet é‡‡ç”¨å­ªç”Ÿç¼–ç å™¨ç»“æ„ï¼Œ

## ğŸš€ ç®€ä»‹ (Introduction)

SAR æ°´ä½“å˜åŒ–æ£€æµ‹é¢ä¸´ç€æ–‘ç‚¹å™ªå£°å¹²æ‰°ã€è¯­ä¹‰äº¤äº’ä¸è¶³ä»¥åŠå¼±è¾¹ç•Œæ¨¡ç³Šç­‰æŒ‘æˆ˜ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº† **WaveDSNet**ã€‚è¯¥ç½‘ç»œåŒ…å«ä»¥ä¸‹æ ¸å¿ƒç»„ä»¶ï¼š

- **WTCSwinTransformer Backbone**: ç»“åˆå°æ³¢å˜æ¢ï¼ˆWavelet Transformï¼‰ä¸ CSwin Transformerï¼Œåˆ©ç”¨ **WNS (Wavelet-based Noise Suppression)** æ¨¡å—åœ¨é¢‘åŸŸä¸­è§£è€¦æ–‘ç‚¹å™ªå£°ä¸ç»“æ„è¯­ä¹‰ ã€‚

  <img src="assert\WTCSWinTransformer.png" alt="image-20251226142349516" style="zoom: 25%;" />

  **å·¥ä½œæµï¼š**é¦–å…ˆï¼Œä½¿ç”¨CSwin Transformerå—å¯¹è¾“å…¥å›¾åƒè¿›è¡Œå¤„ç†ã€‚è¯¥å—é‡‡ç”¨åå­—å½¢çª—å£æ³¨æ„åŠ›æœºåˆ¶ï¼Œèƒ½æ•è·é•¿è·ç¦»ä¾èµ–å…³ç³»ï¼Œç†è§£æ•´ä¸ªåœºæ™¯çš„è¯­ä¹‰ï¼ˆå¦‚æ°´åŸŸã€é™†åœ°ï¼‰ï¼›éšåï¼Œç‰¹å¾å›¾è¿›å…¥å°æ³¢å»å™ªæ¨¡å—ï¼ˆWNSï¼‰ã€‚è¿™é‡Œï¼Œåº”ç”¨ç¦»æ•£å°æ³¢å˜æ¢å°†ç‰¹å¾å›¾åˆ†è§£ä¸ºå››ä¸ªå­å¸¦ï¼š1ä¸ªä½é¢‘å­å¸¦ï¼šä»£è¡¨å›¾åƒçš„æ•´ä½“è½®å»“å’Œå‡åŒ€åŒºåŸŸï¼ˆå¦‚å¹³é™æ°´é¢ï¼‰å’Œ3ä¸ªé«˜é¢‘å­å¸¦ï¼šä»£è¡¨ç»†èŠ‚å’Œè¾¹ç¼˜ï¼Œä½†ä¹ŸåŒ…å«å™ªå£°ã€‚é’ˆå¯¹æ¯ä¸ªå­å¸¦ï¼Œç½‘ç»œç”Ÿæˆè‡ªé€‚åº”çš„å·ç§¯æ ¸ã€‚åœ¨ä½é¢‘åŒºåŸŸï¼Œå·ç§¯æ ¸ç±»ä¼¼å¹³æ»‘å™¨ï¼ŒæŠ‘åˆ¶éšæœºå™ªå£°ï¼›åœ¨é«˜é¢‘è¾¹ç•ŒåŒºåŸŸï¼Œå·ç§¯æ ¸å¢å¼ºè¾¹ç¼˜å“åº”ã€‚è¿™ç§â€œå†…å®¹æ„ŸçŸ¥â€æœºåˆ¶å…è®¸ç½‘ç»œåœ¨ä¸åŒåŒºåŸŸé‡‡ç”¨ä¸åŒç­–ç•¥ï¼Œé¿å…ä¸€åˆ€åˆ‡å»å™ªå¯¼è‡´çš„ç»†èŠ‚ä¸¢å¤±ã€‚å¤„ç†åçš„å­å¸¦é€šè¿‡é€†å°æ³¢å˜æ¢åˆå¹¶ï¼Œå¾—åˆ°å»å™ªåçš„ç‰¹å¾å›¾ã€‚è¿™ä¸€æ­¥ç¡®ä¿å™ªå£°è¢«æŠ‘åˆ¶ï¼ŒåŒæ—¶é‡è¦ç»“æ„ï¼ˆå¦‚ç»†å°æ²³æµï¼‰å¾—ä»¥ä¿ç•™ã€‚

- **CSDI (Complementary Semantic Difference Interaction)**: é€šè¿‡åŒå‘æ³¨æ„åŠ›æœºåˆ¶ï¼Œä¿ƒè¿›è¯­ä¹‰ç‰¹å¾ä¸å·®å¼‚ç‰¹å¾çš„äº’è¡¥èåˆ ã€‚

  <img src="assert\CSDI.png" alt="CSDI" style="zoom: 25%;" />

  å·¥ä½œæµï¼šè¾“å…¥å¤šçº§è¯­ä¹‰ç‰¹å¾å’Œå·®å¼‚ç‰¹å¾ï¼Œåˆ†åˆ«é€šè¿‡å·ç§¯å±‚ç”ŸæˆæŸ¥è¯¢ã€é”®å’Œå€¼å‘é‡ã€‚è¿™ç›¸å½“äºå°†ç‰¹å¾è½¬æ¢ä¸ºé€‚åˆæ³¨æ„åŠ›è®¡ç®—çš„å½¢å¼ã€‚ä¸ºé™ä½è®¡ç®—é‡ï¼Œç‰¹å¾å›¾è¢«åˆ’åˆ†ä¸ºå±€éƒ¨çª—å£ï¼Œæ³¨æ„åŠ›åœ¨çª—å£å†…è®¡ç®—ï¼Œä¿æŒæ•ˆç‡ã€‚åç»è¿‡åŒå‘æ³¨æ„åŠ›è®¡ç®—ï¼š

  â€‹	æ–¹å‘ä¸€ï¼ˆè¯­ä¹‰åˆ°å·®å¼‚ï¼‰ï¼šç”¨è¯­ä¹‰ç‰¹å¾çš„æŸ¥è¯¢å‘é‡ä¸å·®å¼‚ç‰¹å¾çš„é”®å‘é‡äº¤äº’ï¼Œè¯„ä¼°è¯­ä¹‰ä¸Šä¸‹æ–‡å¦‚ä½•å½±å“å˜åŒ–åŒºåŸŸã€‚

  â€‹	æ–¹å‘äºŒï¼ˆå·®å¼‚åˆ°è¯­ä¹‰ï¼‰ï¼šç”¨å·®å¼‚ç‰¹å¾çš„æŸ¥è¯¢å‘é‡ä¸è¯­ä¹‰ç‰¹å¾çš„é”®å‘é‡äº¤äº’ï¼Œè¯„ä¼°å˜åŒ–ä¿¡å·å¦‚ä½•ä¿®æ­£è¯­ä¹‰ç†è§£ã€‚

  ä¸¤ä¸ªæ–¹å‘çš„è¾“å‡ºè¢«æ‹¼æ¥ï¼Œç„¶åé€šè¿‡é—¨æ§æœºåˆ¶ï¼ˆåŸºäºå·ç§¯å’Œæƒé‡ç”Ÿæˆï¼‰è‡ªé€‚åº”èåˆã€‚é—¨æ§æƒé‡å†³å®šæ¯ä¸ªä½ç½®æ›´ä¾èµ–è¯­ä¹‰è¿˜æ˜¯å·®å¼‚ä¿¡æ¯ï¼Œä¾‹å¦‚ï¼Œåœ¨è¾¹ç•ŒåŒºåŸŸèµ‹äºˆå·®å¼‚æ›´é«˜æƒé‡ä»¥å¢å¼ºçµæ•åº¦ã€‚èåˆåçš„ç‰¹å¾å¼ºè°ƒå˜åŒ–ç›¸å…³åŒºåŸŸï¼Œå‡å°‘å™ªå£°å¼•èµ·çš„è¯¯æŠ¥ï¼ˆå¦‚å­£èŠ‚æ€§å¼ºåå°„ï¼‰ã€‚

- **BASE (Boundary-Aware Supervised Extraction)**: æ–½åŠ æ˜¾å¼çš„å‡ ä½•çº¦æŸï¼Œä¼˜åŒ–è¾¹ç•Œå®šä½ç²¾åº¦ ã€‚

  <img src="assert\BASE.png" alt="BASE" style="zoom: 25%;" />
  
  ä¸»åˆ†æ”¯ä¸“æ³¨äºåƒç´ çº§åˆ†ç±»ï¼ˆå˜åŒ–/æœªå˜åŒ–ï¼‰ã€‚å®ƒä½¿ç”¨å·ç§¯å±‚å’Œä¸Šé‡‡æ ·æ“ä½œï¼Œé€æ­¥æ¢å¤åˆ†è¾¨ç‡ï¼Œè¾“å‡ºå˜åŒ–æ¦‚ç‡å›¾ã€‚è¾…åŠ©åˆ†æ”¯ä¸“é—¨æ•è·è¾¹ç•Œã€‚ä¸ºé¿å…ç»†èŠ‚ä¸¢å¤±ï¼Œå®ƒæ—©æœŸåº”ç”¨ä¸Šé‡‡æ ·æ”¾å¤§ç‰¹å¾å›¾ï¼Œå†ç”¨å·ç§¯æå–è¾¹ç¼˜å“åº”ï¼ˆå¦‚æ¢¯åº¦å˜åŒ–ï¼‰ã€‚ä¸¤ä¸ªåˆ†æ”¯å…±äº«ç‰¹å¾ï¼Œä½†å„æœ‰ä¾§é‡ã€‚å˜åŒ–åˆ†æ”¯ç¡®ä¿æ•´ä½“åŒºåŸŸå‡†ç¡®æ€§ï¼Œè¾¹ç¼˜åˆ†æ”¯å¼ºåˆ¶ç½‘ç»œå­¦ä¹ è¾¹ç•Œæ‹“æ‰‘ï¼ˆå¦‚è¿ç»­æ€§ï¼‰ã€‚è®­ç»ƒæ—¶ï¼ŒæŸå¤±å‡½æ•°ç»“åˆå˜åŒ–æŸå¤±å’Œè¾¹ç¼˜æŸå¤±ï¼Œé€šè¿‡æƒé‡å¹³è¡¡ä¸¤è€…è´¡çŒ®ã€‚æœ€ç»ˆå˜åŒ–å›¾èåˆäº†åˆ†æ”¯ç»“æœï¼Œè¾¹ç•Œæ›´å…‰æ»‘ã€è¿è´¯ã€‚ä¾‹å¦‚ï¼Œåœ¨å¼±è¾¹ç•Œå¤„ï¼ˆå¦‚æµ…æ°´åŒºï¼‰ï¼Œè¾¹ç¼˜ç›‘ç£æä¾›é¢å¤–çº¦æŸï¼Œå‡å°‘æ–­è£‚ã€‚
  
  

## ğŸŒŸ ä¸»è¦ç‰¹æ€§ (Main Features)

- **é¢‘åŸŸå»å™ª**: å¼•å…¥å°æ³¢åŠ¨æ€å·ç§¯ï¼Œé’ˆå¯¹ SAR å›¾åƒçš„ä¹˜æ€§å™ªå£°è¿›è¡Œè‡ªé€‚åº”å¤„ç†ã€‚

- **åŒæµååŒ**: è¯­ä¹‰æµä¸å·®å¼‚æµçš„æ·±åº¦äº¤äº’ï¼Œæœ‰æ•ˆå‡å°‘è¯¯æŠ¥ï¼ˆå¦‚ç¨»ç”°ã€é˜´å½±ï¼‰ã€‚

- **é«˜ç²¾åº¦è¾¹ç•Œ**: ä¸“é—¨çš„è¾¹ç¼˜ç›‘ç£åˆ†æ”¯ï¼Œè§£å†³æ°´é™†äº¤ç•Œå¤„çš„æ¨¡ç³Šé—®é¢˜ã€‚

- **SOTA æ€§èƒ½**: åœ¨ XDU-SWCD åŠå…¬å…±æ•°æ®é›†ä¸Šå‡æ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼ˆå¦‚ SFEARNet, DDRL ç­‰ï¼‰ã€‚

  

## ğŸ“Š æ•°æ®é›† (XDU-SWCD Dataset)

ä¸ºäº†è§£å†³æ•°æ®ç¨€ç¼ºé—®é¢˜ï¼Œæˆ‘ä»¬æ„å»ºäº† **XDU-SWCD** æ•°æ®é›† ã€‚

<img src="assert\dataset.png" alt="dataset" style="zoom: 25%;" />

|     **åŒºåŸŸ**      |        **æ—¶é—´**        | **ä¼ æ„Ÿå™¨** | **å°ºå¯¸**  | **åˆ†è¾¨ç‡** | **æ³¢æ®µ** | **æåŒ–æ–¹å¼** | **ç±»åˆ«æ•°** | **è£å‰ªå—æ•°** |
| :---------------: | :--------------------: | :--------: | :-------: | :--------: | :------: | :----------: | :--------: | :----------: |
|     **è¥¿å®‰**      | 2019-01-05  2019-06-29 |  **GF-3**  | 7199Ã—7516 |     3m     |    C     |      HH      |     2      |     870      |
| **è¥¿å®‰**&**å’¸é˜³** | 2019-06-29  2020-09-23 |  **GF-3**  | 5490Ã—8250 |     3m     |    C     |      HH      |     2      |     726      |
|     **å’¸é˜³**      | 2019-06-29  2019-11-04 |  **GF-3**  | 6219Ã—6473 |     3m     |    C     |      HH      |     2      |     650      |
| **å’¸é˜³**&**é“œå·** | 2019-12-03  2020-09-23 |  **GF-3**  | 7393Ã—8266 |     3m     |    C     |      HH      |     2      |     957      |

- **ä¼ æ„Ÿå™¨**: GF-3 (C-æ³¢æ®µ SAR)
- **åˆ†è¾¨ç‡**: 3ç±³ (HH æåŒ–)
- **è§„æ¨¡**: 3,203 å¯¹æ ·æœ¬ (è¦†ç›–è¥¿å®‰ã€å’¸é˜³ã€é“œå·ç­‰æµåŸŸ)
- **æŒ‘æˆ˜**: åŒ…å«æ¯æ°´/ä¸°æ°´æœŸå˜åŒ–ï¼Œä»¥åŠå…·æœ‰è¿·æƒ‘æ€§çš„â€œéš¾è´Ÿæ ·æœ¬â€ï¼ˆå¦‚ç¨»ç”°ã€çŒæº‰åŒºï¼‰ã€‚

ä¸‹è½½é“¾æ¥ï¼š[ç™¾åº¦ç½‘ç›˜](https://pan.baidu.com/s/1lzr1wbQqFq-dxxWaW1NHhg?pwd=vf6e)  | [Google Drive](https://drive.google.com/file/d/1YcoNoKniScIT8QeggGRZXJCP6zRP-fp_/view?usp=drive_link)
## ğŸ› ï¸ å®‰è£…ä¸ç¯å¢ƒ (Installation)

æœ¬é¡¹ç›®åŸºäº PyTorch å¼€å‘ã€‚

```
# å…‹éš†é¡¹ç›®
git clone https://github.com/gosling123456/WaveDSNet.git
cd WaveDSNet

# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
conda create -n waved python=3.10
conda activate waved

# å®‰è£…ä¾èµ–
pip install -r requirements.txt
```

## âš¡ å¿«é€Ÿå¼€å§‹ (Usage)

### 1. æ•°æ®å‡†å¤‡

è¯·æŒ‰ç…§ä»¥ä¸‹ç»“æ„ç»„ç»‡æ•°æ®ï¼š

```
data/
â”œâ”€â”€ XDU-SWCD/
â”‚   â”œâ”€â”€ A/
â”‚   â”œâ”€â”€ B/
â”‚   â”œâ”€â”€ label/
â”‚   â”œâ”€â”€ list/
â”‚   â”‚   â”œâ”€â”€ train.txt/
â”‚   â”‚   â”œâ”€â”€ test.txt/
â”‚   â”‚   â”œâ”€â”€ val.txt/
```

### 2. è®­ç»ƒ (Training)

Bash

```
python train.py --dataset XDU-SWCD --batch_size 16 --lr 1e-3 --epochs 100
```

*(æ³¨ï¼šè¶…å‚æ•°å‚è€ƒè®ºæ–‡ Exper A éƒ¨åˆ†ï¼šLR=1e-3, Batch=16, GPUs=2x RTX 5090, Optimizer=AdamW)* 



### 3. æµ‹è¯• (Testing)

Bash

```
python test.py --checkpoint checkpoints/best_model.pth --output_dir results/
```

## ğŸ“ˆ å®éªŒç»“æœ (Results)

### 1. åœ¨è¥¿å®‰æ•°æ®é›†ä¸Šçš„æµ‹è¯•ç»“æœ

<img src="assert\xian.png" alt="xian_result" style="zoom: 25%;" />

<img src="assert\Xian_result.png" alt="Xian_result" style="zoom: 100%;" />



### 2. åœ¨å…¬å¼€æ•°æ®é›†ä¸Šçš„é›¶æ ·æœ¬æ³›åŒ–æ€§æµ‹è¯•ç»“æœ

<img src="assert\public.png" alt="public" style="zoom: 25%;" />



<img src="assert\public_result.png" alt="public_result" style="zoom: 100%;" />

## ğŸ”— å¼•ç”¨ (Citation)

å¦‚æœæ‚¨è§‰å¾—æœ¬é¡¹ç›®å¯¹æ‚¨çš„ç ”ç©¶æœ‰æ‰€å¸®åŠ©ï¼Œè¯·è€ƒè™‘å¼•ç”¨æˆ‘ä»¬çš„è®ºæ–‡ï¼š

```
###
```

## ğŸ“„ å¼€æºåè®® (License)

æœ¬é¡¹ç›®éµå¾ª [MIT License](https://www.google.com/search?q=LICENSE).

------



**è”ç³»æ–¹å¼**: å¦‚æœ‰é—®é¢˜ï¼Œè¯·è”ç³» `zlren@xidian.edu.cn` æˆ–æ Issue ã€‚
>>>>>>> 559cc8a13f1597c9acca8e0f2d22b02370e7bb4d
